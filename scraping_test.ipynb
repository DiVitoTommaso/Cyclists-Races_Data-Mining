{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import procyclingstats as pcs\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple, Union\n",
    "from procyclingstats.errors import UnexpectedParsingError\n",
    "from procyclingstats.table_parser import TableParser\n",
    "\n",
    "\n",
    "def parse(self, fields: Union[List[str], Tuple[str, ...]]) -> None:\n",
    "\n",
    "    raw_table = []\n",
    "    for _ in range(self.table_length):\n",
    "        raw_table.append({})\n",
    "\n",
    "    for field in fields:\n",
    "        if field != \"class\":\n",
    "            parsed_field_list = getattr(self, field)()\n",
    "        # special case when field is called class\n",
    "        else:\n",
    "            parsed_field_list = getattr(self, \"class_\")()\n",
    "        # field wasn't found in every table row, so isn't matching table\n",
    "        # rows correctly\n",
    "        if len(parsed_field_list) != self.table_length:\n",
    "            message = f\"Field '{field}' wasn't parsed correctly\"\n",
    "            raise UnexpectedParsingError(message)\n",
    "\n",
    "        for row, parsed_value in zip(raw_table, parsed_field_list):\n",
    "            row[field] = parsed_value\n",
    "\n",
    "    # remove unwanted rows\n",
    "    for row in raw_table:\n",
    "        self.table.append(row)\n",
    "\n",
    "    # if \"time\" in fields and self.table:\n",
    "    # self._make_times_absolute()\n",
    "\n",
    "\n",
    "TableParser.parse = parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rider = pcs.Rider(\"rider/bruno-surra\")\n",
    "rider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_races = pd.read_csv(\"dataset/races.csv\")\n",
    "df_races.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get _url which have negative delta\n",
    "bad_urls = df_races.loc[df_races[\"delta\"] < 0, \"_url\"]\n",
    "bad_urls = bad_urls.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_to_seconds(time):\n",
    "    h, m, s = time.split(\":\")\n",
    "    h = int(h) * 3600\n",
    "    m = int(m) * 60\n",
    "    s = int(s)\n",
    "    sign = -1 if m < 0 or h < 0 or s < 0 else 1\n",
    "    return sign * (abs(h) + abs(m) + abs(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for RACE_URL in bad_urls:\n",
    "    stage = pcs.Stage(f\"race/{RACE_URL}\")\n",
    "    print(stage)\n",
    "    ranking = stage.results(\"rider_url\", \"time\", \"rank\")\n",
    "    # for i in sorted(ranking,key = lambda x: x['rank']):\n",
    "    #    print(i)\n",
    "\n",
    "    # convert ranking to pandas table, ranking is a list of objects\n",
    "    df_ranking = pd.DataFrame(ranking)\n",
    "\n",
    "    df_ranking[\"time\"] = df_ranking[\"time\"].apply(time_to_seconds)\n",
    "\n",
    "    # sum first time to all other negative times\n",
    "    # first time is the time of the winner\n",
    "    first_time = df_ranking[\"time\"].loc[0]\n",
    "\n",
    "    # sum first time to all other negative times\n",
    "    df_ranking[\"time\"] = df_ranking[\"time\"].apply(\n",
    "        lambda x: x if x > 0 else first_time + x\n",
    "    )\n",
    "\n",
    "    df_ranking.loc[0, \"time\"] = 0\n",
    "\n",
    "    df_ranking.rider_url = df_ranking.rider_url.apply(\n",
    "        lambda x: x.split(\"/\")[-1]\n",
    "    )\n",
    "\n",
    "    for i in range(len(df_ranking)):\n",
    "        rider = df_ranking.loc[i, \"rider_url\"]\n",
    "        time = df_ranking.loc[i, \"time\"]\n",
    "\n",
    "        df_races.loc[\n",
    "            (df_races._url == RACE_URL) & (df_races.cyclist == rider),\n",
    "            \"delta\",\n",
    "        ] = time\n",
    "\n",
    "    print(\n",
    "        df_races.loc[\n",
    "            (df_races._url == RACE_URL),\n",
    "            \"delta\",\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if delta contains positive floats\n",
    "print(all(x.is_integer() for x in df_races.delta.dropna()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teams imputation (scraping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try solving the imputation of teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a file for output\n",
    "with open(\"output.txt\", \"w\") as f:\n",
    "    f.write(\"This is the output file for storing prints.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bad_teams = df_races[df_races.cyclist_team.isna()]\n",
    "bad_urls = df_bad_teams._url.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arrivato a 3300 CONTINUA DA LÃ¬\n",
    "with open(\"output.txt\", \"w\") as f:\n",
    "    for idx, url in enumerate(bad_urls):\n",
    "        if idx % 100 == 0:\n",
    "            print(f\"Processing {idx}/{len(bad_urls)}\")\n",
    "        stage = pcs.Stage(f\"race/{url}\")\n",
    "\n",
    "        ranking = stage.results(\"rider_url\", \"rank\", \"team_name\")\n",
    "        df_ranking = pd.DataFrame(ranking)\n",
    "        df_ranking.rider_url = df_ranking.rider_url.apply(\n",
    "            lambda x: x.split(\"/\")[-1]\n",
    "        )\n",
    "        df_url = df_bad_teams[df_bad_teams._url == url]\n",
    "\n",
    "        for i in range(len(df_url)):\n",
    "            rider = df_url.iloc[i].cyclist\n",
    "            try:\n",
    "                team = df_ranking.loc[\n",
    "                    df_ranking.rider_url == rider\n",
    "                ].team_name.values[0]\n",
    "            except IndexError:\n",
    "                print(stage)\n",
    "                print(f\"Rider {rider} not found in ranking\")\n",
    "                f.write(f\"{stage.__str__()}\\n\")\n",
    "                f.write(f\"Rider {rider} not found in ranking\\n\")\n",
    "                continue\n",
    "            df_bad_teams.loc[\n",
    "                (df_bad_teams._url == url) & (df_bad_teams.cyclist == rider),\n",
    "                \"cyclist_team\",\n",
    "            ] = team\n",
    "\n",
    "        # check if for this url all teams are filled\n",
    "        # assert all(df_bad_teams[df_bad_teams._url == url].cyclist_team.notna())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the results\n",
    "df_bad_teams.to_csv(\"dataset/bad_teams_2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bad_teams.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
