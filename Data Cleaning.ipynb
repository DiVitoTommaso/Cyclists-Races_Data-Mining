{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55696f5d-eabe-4b87-947a-fa3683465e3b",
   "metadata": {},
   "source": [
    "Import the main libraries for this project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "4c02cc8a-7591-484f-b97e-acf1f6f3e81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4e786f-36bb-4d92-a7e7-90f5fdd6062a",
   "metadata": {},
   "source": [
    "Load the datasets to analize them separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "9191ea13-e0b5-4453-93c2-bb3e7db5a086",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's make a preliminary analysis to the datasets\n",
    "races_df = pd.read_csv(\"./dataset/races.csv\")\n",
    "cyclist_df = pd.read_csv(\"./dataset/cyclists.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20ab3ae-e183-42c6-a5db-74b3914ed81d",
   "metadata": {},
   "source": [
    "**Ciclist analysis**\n",
    "The key for cyclist table is column **_url** that is the name of the cyclist, while in races table the column **cyclist** is a foreign key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "9a0d4eaa-57a2-4c46-8089-bbace08bc28d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "def check_key(df, column_name):\n",
    "    # Check if there are no NaN values and if all values are unique\n",
    "    return df[column_name].notna().all() and df[column_name].is_unique\n",
    "def check_in(df1, df2, col1, col2):\n",
    "    return df1[col1].isin(df2[col2]).all()\n",
    "\n",
    "print(check_key(cyclist_df, '_url')) # This column is a key for clyclist dataset\n",
    "print(check_in(races_df, cyclist_df, 'cyclist', '_url')) # These columns can be used for join"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9c52c9-6fda-4d22-9fac-68005eedd8da",
   "metadata": {},
   "source": [
    "Some columns have missing values in the cyclist table. For birth_year and nationality we can try to fix them, while we cannot fix weight and height columns since they are NaN for half of the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "37eea336-43a8-4d19-ae8d-7377bbbed957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6134 entries, 0 to 6133\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   _url         6134 non-null   object \n",
      " 1   name         6134 non-null   object \n",
      " 2   birth_year   6121 non-null   float64\n",
      " 3   weight       3078 non-null   float64\n",
      " 4   height       3143 non-null   float64\n",
      " 5   nationality  6133 non-null   object \n",
      "dtypes: float64(3), object(3)\n",
      "memory usage: 287.7+ KB\n"
     ]
    }
   ],
   "source": [
    "cyclist_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6b2cc4-3b58-4508-b905-b399b2d4ed91",
   "metadata": {},
   "source": [
    "Only cyclist **scott-davies** has missing nationality. We can fix its nationality and birth_year by looking on the web."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "7940ed00-fdd7-4436-b55d-dbfa3e1602b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           _url           name  birth_year  weight  height nationality\n",
      "9  scott-davies  Scott  Davies         NaN     NaN     NaN         NaN\n"
     ]
    }
   ],
   "source": [
    " # Only one cyclist has nan nationality.\n",
    "print(cyclist_df.loc[cyclist_df.nationality[cyclist_df.nationality.isna()].index])\n",
    "def fix_cyclist(df):\n",
    "    mask = df['nationality'].isna()\n",
    "    cyclists = set(df.loc[mask, '_url'])\n",
    "    for c in cyclists:\n",
    "        mask = df[\"_url\"] == c\n",
    "        df.loc[mask, 'nationality'] = 'Britain'\n",
    "        df.loc[mask, 'birth_year'] = 1995\n",
    "\n",
    "# Fix using Wikipedia\n",
    "fix_cyclist(cyclist_df)\n",
    "print(cyclist_df.loc[cyclist_df.nationality[cyclist_df._url == 'scott-davies'].index])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88da566-2c3c-4366-a358-5d53f84b1def",
   "metadata": {},
   "source": [
    "These cyclist instead have missing birth_year, they are few we can try to fix them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d49a37-15a6-48d4-9d53-7ddb630abeb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cyclist_df.loc[cyclist_df.birth_year[cyclist_df.birth_year.isna()].index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21853d2-b766-4533-80d7-23c810acba3c",
   "metadata": {},
   "source": [
    "**Races analysis**\n",
    "Some columns have missing values in races table (**points**, **uci_points**, **climb_total**, **profile**, **average_temperature**, **cyclist_age**, **cycilist_team**).\n",
    "\n",
    "We can try to fix columns **points**, **cyclist_age** since there are few missing values.\n",
    "We can drop the column **average_temperature** since there are too many missing values.\n",
    "We can try to analyze the distribution of **climb_total** over **profile** to try to esitimate and fix the columns.\n",
    "We can assume that missing values if **cyclist_team** implies 'No team'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "1a5d40c2-e081-4dd4-bca8-ff6a2e89fb73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 589865 entries, 0 to 589864\n",
      "Data columns (total 18 columns):\n",
      " #   Column               Non-Null Count   Dtype  \n",
      "---  ------               --------------   -----  \n",
      " 0   _url                 589865 non-null  object \n",
      " 1   name                 589865 non-null  object \n",
      " 2   points               589388 non-null  float64\n",
      " 3   uci_points           251086 non-null  float64\n",
      " 4   length               589865 non-null  float64\n",
      " 5   climb_total          442820 non-null  float64\n",
      " 6   profile              441671 non-null  float64\n",
      " 7   startlist_quality    589865 non-null  int64  \n",
      " 8   average_temperature  29933 non-null   float64\n",
      " 9   date                 589865 non-null  object \n",
      " 10  position             589865 non-null  int64  \n",
      " 11  cyclist              589865 non-null  object \n",
      " 12  cyclist_age          589752 non-null  float64\n",
      " 13  is_tarmac            589865 non-null  bool   \n",
      " 14  is_cobbled           589865 non-null  bool   \n",
      " 15  is_gravel            589865 non-null  bool   \n",
      " 16  cyclist_team         430704 non-null  object \n",
      " 17  delta                589865 non-null  float64\n",
      "dtypes: bool(3), float64(8), int64(2), object(5)\n",
      "memory usage: 69.2+ MB\n"
     ]
    }
   ],
   "source": [
    "races_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1e4140-580f-4dcc-88ca-7ca9b510d081",
   "metadata": {},
   "source": [
    "There is some noise in the date we can remove the hours, minutes and seconds of start of the races"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "0debdf00-bd1b-4a05-9b09-928dab380d94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[datetime.date(1978, 7, 5) datetime.date(2016, 9, 3)\n",
      " datetime.date(2019, 7, 28) ... datetime.date(1976, 3, 9)\n",
      " datetime.date(2016, 3, 27) datetime.date(2010, 5, 8)]\n"
     ]
    }
   ],
   "source": [
    "# Let's remove the noise from dates of races\n",
    "def reformat_dates(df):\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    return df['date'].dt.date\n",
    "\n",
    "races_df['date'] = reformat_dates(races_df)\n",
    "print(races_df['date'].unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee41290-9cd0-4dc7-a05c-1f7f5d603d32",
   "metadata": {},
   "source": [
    "We can try to check if **points** column is mutually eclusive with **uci_points** column. They aren't"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "2beafaef-3b6b-4086-8013-a103afbcbc83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "# Points and UCI_Points are not mutually exclusive columns\n",
    "def are_xor_columns(df, col1, col2):\n",
    "    mask = df[col1].isna() ^ df[col2].isna()\n",
    "    res = df.loc[mask, 'cyclist'].tolist()\n",
    "    return len(res) == len(df)\n",
    "\n",
    "print(are_xor_columns(races_df, 'points', 'uci_points'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112d72db-40b4-4ecc-b816-fed20b98594c",
   "metadata": {},
   "source": [
    "**is_cobbled** and **is_gravel** are all false (we can drop them).\n",
    "**is_tarmac** is sometimes true and false. It's ok but when it's false also the other columns are false (Noise!!). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "bdc75499-bdce-44a7-b275-d68fd9626ff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False]\n",
      "[False]\n",
      "[ True False]\n"
     ]
    }
   ],
   "source": [
    "# Some columns are all False\n",
    "print(races_df.is_cobbled.unique())\n",
    "print(races_df.is_gravel.unique())\n",
    "print(races_df.is_tarmac.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8dab0f-772f-4cd0-81b8-b0b9c9134928",
   "metadata": {},
   "outputs": [],
   "source": [
    "The delta column have some negative values and also the delta is 0 for many positions different from 0 (Very noisy column!!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "05846d42-025d-4929-b8b9-25b84ecba5c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-6906.0, -5562.0, -2937.0, -2638.0, -2635.0, -2574.0, -2567.0, -2564.0, -2560.0, -2550.0, -2546.0, -2545.0, -2542.0, -2541.0, -2514.0, -2513.0, -2510.0, -2509.0, -2505.0, -2504.0, -2500.0, -2487.0, -2486.0, -2485.0, -2482.0, -2481.0, -2479.0, -2477.0, -2475.0, -2473.0, -2469.0, -2457.0, -2448.0, -2446.0, -2444.0, -2440.0, -2438.0, -2437.0, -2434.0, -2432.0, -2430.0, -2428.0, -2425.0, -2424.0, -2419.0, -2416.0, -2413.0, -2410.0, -2408.0, -2397.0, -2394.0, -2393.0, -2391.0, -2385.0, -2384.0, -2378.0, -2367.0, -2365.0, -2359.0, -2358.0, -2356.0, -2355.0, -2353.0, -2352.0, -2349.0, -2348.0, -2346.0, -2345.0, -106.0, 0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0]\n"
     ]
    }
   ],
   "source": [
    "#A column has inconsistent values. (Negative delta)\n",
    "print(sorted(races_df.delta.unique())[:100])\n",
    "# Replace negative values with nan\n",
    "races_df['delta'] = races_df['delta'].mask(races_df['delta'] < 0, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be307170-0dd5-4a24-b933-8f4ddc249588",
   "metadata": {},
   "outputs": [],
   "source": [
    "First position in a race is 0. We can check it looking on the web."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "3b065369-d9f6-4d29-855e-9fd7e72f0d55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5281\n",
      "2738\n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 104]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 199, 200, 201, 202, 203, 204]\n"
     ]
    }
   ],
   "source": [
    "# First position in a race is 0. Delta is always 0 for position 0 and different from 0 for position. Checked using Internet\n",
    "delta0 = ((races_df['position'] == 0) & (races_df['delta'] == 0)).sum()\n",
    "delta1 = ((races_df['position'] == 1) & (races_df['delta'] == 0)).sum()\n",
    "print(delta0)\n",
    "print(delta1)\n",
    "\n",
    "# Much Much noise in delta column. All positions have some 0 deltas\n",
    "positions = sorted(races_df.loc[races_df['delta'].isna(), 'position'].unique())\n",
    "print(positions)\n",
    "positions = sorted(races_df.loc[races_df['delta'] == 0, 'position'].unique())\n",
    "print(positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b0316a-210c-4766-aa67-56411dac20b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Some races have missing profiles. Try to fix looking to the climb_total distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "8c761d15-bac3-4203-a865-ba4681e19613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  5. nan  3.  2.  4.]\n"
     ]
    }
   ],
   "source": [
    "# Profile is numerical (difficulty of trace) missing for some races\n",
    "print(races_df.profile.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3cd36b-dd57-4f81-b386-3a04c48e93b0",
   "metadata": {},
   "source": [
    "The startlist are integers representing how strong the lineup is. They are sparse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "76ef62aa-3adf-4a63-a545-1aace14ddf7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1241,  821, 1699,  804, 1551,  899,  659,  388,  900,  541,  830,\n",
       "        789,  602,  817, 1400, 1161, 1040,  896,  791,  819,  670,  225,\n",
       "        520, 1057,  809,  828,  722,  747,  714,  815,  376,  621,  760,\n",
       "        798,  933, 1994, 1437, 1362,  884, 1150,  971,  881, 1112, 1175,\n",
       "        891,  878,  400,  936,  692,  727, 1002,  928, 1196, 1489,  687,\n",
       "        585,  835,  673, 1328,  885,  502,  861,  982,  923, 1036, 1690,\n",
       "        925,  989, 1109, 1084,  803,  792,  548,  668, 1713, 1520, 1959,\n",
       "        883,  859, 2047, 1024,  533, 1269,  751, 1202,  570, 1703, 1416,\n",
       "        251, 1158, 1139,  657, 1048,  521, 1034, 1099,  880, 1029,  627,\n",
       "        340], dtype=int64)"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "races_df.startlist_quality.unique()[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2bed373-3b05-4b4a-b9a6-fb4465d75f84",
   "metadata": {},
   "source": [
    "Now we can build the joined table and analyze the data together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "23814a28-0375-49b9-9a6a-a31c1336fa56",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataCleaner:\n",
    "    def __init__(self, races_csv, cyclist_csv, merged_csv=None):\n",
    "        # So keep ref to all datasets and make one joined\n",
    "        self.races_df = pd.read_csv(races_csv, parse_dates=[\"date\"])\n",
    "        self.cyclist_df = pd.read_csv(cyclist_csv)\n",
    "\n",
    "        if merged_csv == None:\n",
    "            self.df = pd.merge(\n",
    "                self.races_df, self.cyclist_df, left_on=\"cyclist\", right_on=\"_url\", how=\"inner\"\n",
    "            )\n",
    "        else:\n",
    "            self.df = pd.read_csv(merged_csv, parse_dates=[\"date\"])\n",
    "\n",
    "        # Delete useless columns\n",
    "        self.delete_column(\"_url_y\")\n",
    "        self.delete_column(\"name_y\")\n",
    "\n",
    "        # Delete columns that are all false\n",
    "        self.delete_column(\"is_cobbled\")\n",
    "        self.delete_column(\"is_gravel\")\n",
    "\n",
    "        # Rename to understand better\n",
    "        self.df.rename(\n",
    "            columns={\n",
    "                \"name_x\": \"location\",\n",
    "                \"_url_x\": \"url\",\n",
    "            },\n",
    "            inplace=True,\n",
    "        )\n",
    "\n",
    "        dm.export_csv() # Save the merged version of dataset  \n",
    "    def delete_column(self, col):\n",
    "        self.df.drop(columns=[col], inplace=True)\n",
    "    def fill_nan(self, column, value):\n",
    "        self.df[column].fillna(value, inplace=True)\n",
    "    def export_csv(self):\n",
    "        return self.df.to_csv(\"./dataset/dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "70905c13-5887-48df-9909-6a19115aed7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = DataCleaner(\"./dataset/races.csv\", \"./dataset/cyclists.csv\") # Initialize the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "91071437-cbcc-4979-a8f6-b25649c668ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 589865 entries, 0 to 589864\n",
      "Data columns (total 20 columns):\n",
      " #   Column               Non-Null Count   Dtype         \n",
      "---  ------               --------------   -----         \n",
      " 0   url                  589865 non-null  object        \n",
      " 1   location             589865 non-null  object        \n",
      " 2   points               589388 non-null  float64       \n",
      " 3   uci_points           251086 non-null  float64       \n",
      " 4   length               589865 non-null  float64       \n",
      " 5   climb_total          442820 non-null  float64       \n",
      " 6   profile              441671 non-null  float64       \n",
      " 7   startlist_quality    589865 non-null  int64         \n",
      " 8   average_temperature  29933 non-null   float64       \n",
      " 9   date                 589865 non-null  datetime64[ns]\n",
      " 10  position             589865 non-null  int64         \n",
      " 11  cyclist              589865 non-null  object        \n",
      " 12  cyclist_age          589752 non-null  float64       \n",
      " 13  is_tarmac            589865 non-null  bool          \n",
      " 14  cyclist_team         430704 non-null  object        \n",
      " 15  delta                589865 non-null  float64       \n",
      " 16  birth_year           589752 non-null  float64       \n",
      " 17  weight               478431 non-null  float64       \n",
      " 18  height               479746 non-null  float64       \n",
      " 19  nationality          589813 non-null  object        \n",
      "dtypes: bool(1), datetime64[ns](1), float64(11), int64(2), object(5)\n",
      "memory usage: 86.1+ MB\n"
     ]
    }
   ],
   "source": [
    "dm.df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "9c0779ac-fd41-45be-9277-c8217fc72cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 alexandr-osipov\n",
      "2536   NaN\n",
      "Name: birth_year, dtype: float64\n",
      "1 antonio-zanini\n",
      "894   NaN\n",
      "Name: birth_year, dtype: float64\n",
      "2 batik-odriozola\n",
      "6080   NaN\n",
      "Name: birth_year, dtype: float64\n",
      "3 carlos-garcia\n",
      "2515   NaN\n",
      "Name: birth_year, dtype: float64\n",
      "4 filippo-simonetti\n",
      "2408   NaN\n",
      "Name: birth_year, dtype: float64\n",
      "5 javier-luquin\n",
      "4384   NaN\n",
      "Name: birth_year, dtype: float64\n",
      "6 nevens-guy\n",
      "3551   NaN\n",
      "Name: birth_year, dtype: float64\n",
      "7 nicolai-kosyakov\n",
      "3046   NaN\n",
      "Name: birth_year, dtype: float64\n",
      "8 oscar-pumar\n",
      "4142   NaN\n",
      "Name: birth_year, dtype: float64\n",
      "9 scott-davies\n",
      "9    1995.0\n",
      "Name: birth_year, dtype: float64\n",
      "10 sergei-jermachenko\n",
      "6072   NaN\n",
      "Name: birth_year, dtype: float64\n",
      "11 thierry-lauder\n",
      "4756   NaN\n",
      "Name: birth_year, dtype: float64\n",
      "12 vladimir-malakov\n",
      "601   NaN\n",
      "Name: birth_year, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Try to fix missing birth_year or age using the other column. Nothing they always nan at the same time\n",
    "\n",
    "ages = dm.df.groupby('cyclist')['cyclist_age'].unique()\n",
    "\n",
    "ages = ages.apply(lambda x: np.isnan(x).all())\n",
    "# names for which is true\n",
    "ages = ages[ages == True].index\n",
    "\n",
    "for idx, name in enumerate(ages):\n",
    "    print(idx,name)\n",
    "    print(cyclist_df.loc[cyclist_df._url == name].birth_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5956a243-c86d-4dfa-bb7a-b4d48d2a3bf1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516005c4-78d6-4045-b520-bc7a51a53bf6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f672877-bc64-484e-ab8d-c6d83a08baad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a7bca5-0fcb-4391-87ac-473d809c9ae5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bb3f4a-29f6-4e4a-bc97-6a9369f633fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1e5c8a-1fdf-453d-b984-afe8296d74e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3479f42-e6ea-4732-ae20-9f6e383423c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1042287-f70b-4b45-94fd-122b8295aa0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3609a982-3598-463d-932f-b8f7aed8b27e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3752af87-53ff-4b58-b32e-ce9a7cf132fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
